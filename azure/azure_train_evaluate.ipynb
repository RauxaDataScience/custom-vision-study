{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Dataset Evaluation Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import clarifai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage:\n",
    "1. Replace root_data with path to datasets\n",
    "2. Insert training key for your project\n",
    "3. Insert prediction key for your project\n",
    "4. Comment out any dataset_domains in dict that you're not interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_sets = []  # List ones to skip here\n",
    "\n",
    "root_data = '{PATH_TO_ROOT_DATASETS}'\n",
    "n_batch = 64\n",
    "max_total = 50000\n",
    "\n",
    "# Replace with keys\n",
    "training_key = '{TRAINING_KEY}'\n",
    "prediction_key = '{PREDICTION_KEY}'\n",
    "\n",
    "# Hardcoded URLs. Needs updating if API updates are made\n",
    "url_train = 'https://southcentralus.api.cognitive.microsoft.com/customvision/v2.0/Training'\n",
    "url_pred = 'https://southcentralus.api.cognitive.microsoft.com/customvision/v2.0/Prediction'\n",
    "\n",
    "# It's suggested you select the appropriate domain for your dataset\n",
    "retail_domain_id = 'b30a91ae-e3c1-4f73-a81e-c270bff27c39'\n",
    "general_domain_id = 'ee85a74c-405e-4adc-bb47-ffa8ca0c9f31'\n",
    "\n",
    "dataset_domains = {\n",
    "    'fashion_mnist_10p': general_domain_id,    \n",
    "    'cifar10_20p': general_domain_id,    \n",
    "    'uo_dress': retail_domain_id,\n",
    "    'cifar10': general_domain_id,\n",
    "    'fashion_mnist': general_domain_id,\n",
    "    'mnist': general_domain_id\n",
    "    'fashion_mnist_tiny': general_domain_id,    \n",
    "    'cifar10_tiny': general_domain_id,    \n",
    "    'uo_dress_tiny': retail_domain_id,\n",
    "    'mnist_tiny': general_domain_id    \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "header_train = {'Training-Key': training_key}\n",
    "header_pred = {'Prediction-Key': prediction_key}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yield successive n-sized chunks from l. \n",
    "def divide_chunks(l, n):      \n",
    "    # looping till length l \n",
    "    for i in range(0, len(l), n):  \n",
    "        yield l[i:i + n] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main train/test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(dataset_path, domain_id):\n",
    "    labels = pd.read_csv(os.path.join(dataset_path, 'labels.csv'), header=None, dtype=str)\n",
    "    train_files = labels[labels[0].str.contains('(train|val)')].values\n",
    "    test_files = labels[labels[0].str.contains('test')].values    \n",
    "    \n",
    "    y_train = train_files[:,1]\n",
    "    class_labels = np.sort(np.unique(y_train))\n",
    "    \n",
    "    # Create a new project\n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "    project_name = '{}_{}'.format(d, timestamp)\n",
    "    url_create = '{}/projects'.format(url_train)\n",
    "    params = {'name': project_name,\n",
    "              'domainId': domain_id\n",
    "             }\n",
    "\n",
    "    # Call the API\n",
    "    print(url_create)\n",
    "    r = requests.post(url_create, headers=header_train, params=params)\n",
    "    print(r.status_code)\n",
    "\n",
    "    # Get ID\n",
    "    project_id = r.json()['id']\n",
    "    print('Project Name: {}. ID: {}'.format(project_name, project_id)) \n",
    "    \n",
    "    project_settings = r.json()\n",
    "    print(project_settings)\n",
    "    \n",
    "    \n",
    "    # Assign to multi-class instead of multi-label\n",
    "    url_project = '{}/projects/{}'.format(url_train, project_id)\n",
    "    print(url_project)\n",
    "    project_settings['settings']['classificationType'] = 'Multiclass'\n",
    "    r = requests.patch(url_project, headers=header_train, data=json.dumps(project_settings))\n",
    "    print(r)\n",
    "\n",
    "    # Create tags\n",
    "    tag_ids = {}\n",
    "    url_tag = '{}/projects/{}/tags'.format(url_train, project_id)\n",
    "    for c in class_labels:\n",
    "        params = {'name': c}\n",
    "        r = requests.post(url_tag, headers=header_train, params=params)\n",
    "        tag_ids[c] = r.json()['id']\n",
    "        print(c, tag_ids[c], r)\n",
    "\n",
    "\n",
    "\n",
    "    # Load in files for training\n",
    "\n",
    "    # Set up base url\n",
    "    url_upload = '{}/projects/{}/images'.format(url_train, project_id)\n",
    "\n",
    "    # Get all matching files for this class (to batch upload)\n",
    "    max_per_class = (max_total/len(class_labels))-1\n",
    "    for cls in class_labels:\n",
    "        print('Uploading files from class: {} ...'.format(cls))\n",
    "        inds_match = y_train == cls\n",
    "        files_temp = train_files[inds_match, 0]\n",
    "        y_temp = y_train[inds_match]\n",
    "        files_temp = [os.path.join(dataset_path, c) for c in files_temp]\n",
    "        print('{} files found.'.format(len(files_temp)))\n",
    "\n",
    "        # Chunk up in groups of 64\n",
    "        chunks = list(divide_chunks(files_temp, n_batch))\n",
    "        for i,chunk in enumerate(chunks):\n",
    "            print('Bulk upload chunk {} of {} ({} items) ...'.format(i+1, len(chunks), len(chunk)))\n",
    "\n",
    "            # Open handles for bulk upload\n",
    "            handles = {}\n",
    "            for f in chunk:\n",
    "                basename = os.path.basename(f)\n",
    "                handles[basename] = open(f, 'rb')\n",
    "\n",
    "            # Assign tag from lookup\n",
    "            params = {'tagIds': tag_ids[cls]}\n",
    "\n",
    "            # Make the request and print resonse status\n",
    "            r = requests.post(url_upload, headers=header_train, params=params, files=handles)\n",
    "            print(r)\n",
    "\n",
    "            # Close the handles\n",
    "            for k,v in handles.items():\n",
    "                v.close()  \n",
    "            \n",
    "            # Don't upload past max per class\n",
    "            if (i+1)*n_batch > (max_per_class-n_batch):\n",
    "                break\n",
    "\n",
    "    # Train the model\n",
    "    url_run_training = '{}/projects/{}/train'.format(url_train, project_id)\n",
    "    r = requests.post(url_run_training, headers=header_train)\n",
    "    print(r)\n",
    "    print(r.json)\n",
    "\n",
    "    # Assign model ID\n",
    "    model_id = r.json()['id']\n",
    "    print('Trained Model ID: {}'.format(model_id))\n",
    "\n",
    "\n",
    "    # Wait for training to complete\n",
    "    url_status = '{}/projects/{}/iterations'.format(url_train, project_id)\n",
    "\n",
    "    # Loop and wait for training to complete\n",
    "    max_tries = 60\n",
    "    wait_cnt = 0\n",
    "    while wait_cnt < max_tries:\n",
    "        print('Try #{} of {}...'.format(wait_cnt+1, max_tries))\n",
    "        r = requests.get(url_status, headers=header_train)\n",
    "        try:\n",
    "            status = r.json()[0]['status']\n",
    "        except:\n",
    "            status = 'error'\n",
    "        print(r)\n",
    "        if status == 'Completed':\n",
    "            print('Training Complete!')\n",
    "            break\n",
    "        print('Status: {}. Waiting for model training to complete ...'.format(status))\n",
    "        time.sleep(30)\n",
    "        wait_cnt += 1\n",
    "\n",
    "    # Save off iteration ID for prediction\n",
    "    iteration_id = r.json()[0]['id']\n",
    "    print('Iteration ID: {}'.format(iteration_id))\n",
    "\n",
    "\n",
    "    # Assign ground truth for test\n",
    "    y_true = test_files[:,1]\n",
    "\n",
    "\n",
    "    # Load in files for prediction \n",
    "\n",
    "    # Set up base url\n",
    "    #url_query = '{}/{}/image'.format(url_pred, project_id) # with storing\n",
    "    url_query = '{}/{}/image/nostore'.format(url_pred, project_id)  # No storing\n",
    "    params = {'iterationId': iteration_id}\n",
    "\n",
    "    # Chunk it up!\n",
    "    y_pred = []\n",
    "    scores = []\n",
    "    handle = {}\n",
    "    test_filenames = test_files[:, 0]\n",
    "    test_filenames = [os.path.join(dataset_path, c) for c in test_filenames]\n",
    "    print('{} prediction files found.'.format(len(test_filenames)))\n",
    "\n",
    "    def predict_worker(filename):\n",
    "        basename = os.path.basename(filename)\n",
    "        handle['imageData'] = open(filename, 'rb') \n",
    "        r = requests.post(url_query, headers=header_pred, params=params, files=handle)\n",
    "        handle['imageData'].close() # Close the handle and move on   \n",
    "\n",
    "        # Error check\n",
    "        t_pred = None\n",
    "        t_scores = None\n",
    "        if r.status_code == 200:\n",
    "            # Extract predictions\n",
    "            out = r.json()\n",
    "            pred_set = out['predictions']\n",
    "\n",
    "            # Get sorted scores from prediction set\n",
    "            t_names = np.array([z['tagName'] for z in pred_set])\n",
    "            t_scores = np.array([z['probability'] for z in pred_set])\n",
    "            sort_inds = np.argsort(t_names)\n",
    "            t_names = t_names[sort_inds]\n",
    "            t_scores = t_scores[sort_inds]\n",
    "            t_pred = t_names[np.argmax(t_scores)]\n",
    "        else:\n",
    "            print('Error occured on prediction: {}. Skipping save.'.format(filename))\n",
    "\n",
    "        return basename, t_pred, t_scores\n",
    "\n",
    "\n",
    "    # Run parallel calls to make faster\n",
    "    t_start = time.time()\n",
    "    with Parallel(n_jobs=-1, verbose=5) as parallel:\n",
    "        n_iter = 0\n",
    "        results = parallel(delayed(predict_worker)(f) for f in test_filenames)\n",
    "    t_elapsed = time.time() - t_start\n",
    "    print(len(results))\n",
    "    print('{:0.3f} secs elapsed for predicting {} images'.format(t_elapsed, len(test_filenames)))\n",
    "\n",
    "    # Parse the parallel output\n",
    "    returned_files = [r[0] for r in results]\n",
    "    y_pred = [r[1] for r in results]\n",
    "    scores = [r[2] for r in results]\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    print('Number of predictions: {}'.format(len(y_pred)))\n",
    "    print('Number of fails: {}.'.format(sum([yy is None for yy in y_pred])))\n",
    "\n",
    "\n",
    "    #\n",
    "    # Save results\n",
    "    #\n",
    "    save_file = '{}-results.p'.format(project_name)\n",
    "    save_dict = {\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'scores': scores,\n",
    "        'class_labels': class_labels,\n",
    "        'model_name': project_name,\n",
    "        'model': None,\n",
    "        'train_files': train_files,\n",
    "        'test_files': test_files,\n",
    "        'returned_files': returned_files\n",
    "        }\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(save_dict, f)\n",
    "    print('Saved to {}'.format(save_file))\n",
    "\n",
    "    return save_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Train/Test on Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d,domain_id in dataset_domains.items():\n",
    "    if d in skip_sets:\n",
    "        continue\n",
    "        \n",
    "    # Get dataset key and directory\n",
    "    dataset_path = os.path.join(root_data, d)\n",
    "    print('EXECUTING DATASET: {}'.format(dataset_path))    \n",
    "    \n",
    "    # Run mega routine\n",
    "    train_and_test(dataset_path, domain_id)\n",
    "    \n",
    "    # Output\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
